{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYq9IoCOQ1wjyaHagNVah/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"],"metadata":{"id":"qnsWYAXTuRPk"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"NVECZIAIF2LQ"}},{"cell_type":"code","source":["# !pip install tensorflow==2.10"],"metadata":{"id":"EUBN4dZ6nGAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Y7PnJ0cRFfzu","executionInfo":{"status":"ok","timestamp":1677799141556,"user_tz":300,"elapsed":3501,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"outputs":[],"source":["import pathlib\n","import random\n","import string\n","import re\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization"]},{"cell_type":"code","source":["tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wcsp_PfbnNdK","executionInfo":{"status":"ok","timestamp":1677799141556,"user_tz":300,"elapsed":6,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"7daed5ce-382a-4efa-8599-6b9842c815be"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.10.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["#Downloading the data"],"metadata":{"id":"aySkY3I3F0lI"}},{"cell_type":"code","source":["text_file = keras.utils.get_file(\n","    fname=\"spa-eng.zip\",\n","    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n","    extract=True,\n",")\n","text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pWIFVOYFujO","executionInfo":{"status":"ok","timestamp":1677799148418,"user_tz":300,"elapsed":1905,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"c245aef8-e45c-454c-e48d-374ead23c98f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","2638744/2638744 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["# Parsing the data"],"metadata":{"id":"vlrXQpTjFvyy"}},{"cell_type":"code","source":["with open(text_file) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","text_pairs = []\n","for line in lines:\n","    eng, spa = line.split(\"\\t\")\n","    spa = \"[start] \" + spa + \" [end]\"\n","    text_pairs.append((eng, spa))"],"metadata":{"id":"MZldacqzF5mX","executionInfo":{"status":"ok","timestamp":1677799154252,"user_tz":300,"elapsed":308,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["for _ in range(5):\n","    print(random.choice(text_pairs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ny1rm-0F7Le","executionInfo":{"status":"ok","timestamp":1677799155813,"user_tz":300,"elapsed":3,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"a44bad2d-213a-47f3-c76a-b16c8d86378c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["('Students should make use of the books in the library.', '[start] Los estudiantes deberían utilizar los libros de la biblioteca. [end]')\n","('Maybe Tom likes swimming.', '[start] Quizá a Tom le guste nadar. [end]')\n","('Tom climbed down from the roof.', '[start] Tom se bajó del techo. [end]')\n","('Do you want a few more minutes?', '[start] ¿Quieres unos minutos más? [end]')\n","('Tom asked me if I knew anybody who could translate from French into English.', '[start] Tom me preguntó si conocía a alguien que pudiera traducir de francés a inglés. [end]')\n"]}]},{"cell_type":"code","source":["random.shuffle(text_pairs)\n","num_val_samples = int(0.15 * len(text_pairs))\n","num_train_samples = len(text_pairs) - 2 * num_val_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n","test_pairs = text_pairs[num_train_samples + num_val_samples :]\n","\n","print(f\"{len(text_pairs)} total pairs\")\n","print(f\"{len(train_pairs)} training pairs\")\n","print(f\"{len(val_pairs)} validation pairs\")\n","print(f\"{len(test_pairs)} test pairs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-gmMmXDF7_i","executionInfo":{"status":"ok","timestamp":1677799160809,"user_tz":300,"elapsed":329,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"c273c769-9df1-480c-e9d5-95790fb00a4c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["118964 total pairs\n","83276 training pairs\n","17844 validation pairs\n","17844 test pairs\n"]}]},{"cell_type":"markdown","source":["# Vectorizing the text data"],"metadata":{"id":"AtLLrPLqF9tu"}},{"cell_type":"code","source":["strip_chars = string.punctuation + \"¿\"\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")\n","\n","vocab_size = 15000\n","sequence_length = 20\n","batch_size = 64\n","\n","\n","def custom_standardization(input_string):\n","    lowercase = tf.strings.lower(input_string)\n","    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","\n","\n","eng_vectorization = TextVectorization(\n","    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",")\n","spa_vectorization = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")\n","train_eng_texts = [pair[0] for pair in train_pairs]\n","train_spa_texts = [pair[1] for pair in train_pairs]\n","eng_vectorization.adapt(train_eng_texts)\n","spa_vectorization.adapt(train_spa_texts)"],"metadata":{"id":"b8ddDj5-F__x","executionInfo":{"status":"ok","timestamp":1677800282053,"user_tz":300,"elapsed":18151,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def format_dataset(eng, spa):\n","    eng = eng_vectorization(eng)\n","    spa = spa_vectorization(spa)\n","    return ({\"encoder_inputs\": eng, \"decoder_inputs\": spa[:, :-1],}, spa[:, 1:])\n","\n","\n","def make_dataset(pairs):\n","    eng_texts, spa_texts = zip(*pairs)\n","    eng_texts = list(eng_texts)\n","    spa_texts = list(spa_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.shuffle(2048).prefetch(16).cache()\n","\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"],"metadata":{"id":"MQW9JmEaGBoE","executionInfo":{"status":"ok","timestamp":1677800283474,"user_tz":300,"elapsed":1435,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYnXu6QVGFiL","executionInfo":{"status":"ok","timestamp":1677800287225,"user_tz":300,"elapsed":870,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"956ff549-b315-4fdc-94eb-8e41ad76ff8a"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs[\"encoder_inputs\"].shape: (64, 20)\n","inputs[\"decoder_inputs\"].shape: (64, 20)\n","targets.shape: (64, 20)\n"]}]},{"cell_type":"code","source":["for inputs, targets in val_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQ9CwxBFYNs7","executionInfo":{"status":"ok","timestamp":1677799216399,"user_tz":300,"elapsed":299,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"a8d89298-ee50-4f0c-c180-88d43bf11d2a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs[\"encoder_inputs\"].shape: (64, 20)\n","inputs[\"decoder_inputs\"].shape: (64, 20)\n","targets.shape: (64, 20)\n"]}]},{"cell_type":"markdown","source":["# Building the model"],"metadata":{"id":"kjBtgn4vGHar"}},{"cell_type":"code","source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)"],"metadata":{"id":"2pXzMSYFGJvq","executionInfo":{"status":"ok","timestamp":1677800311494,"user_tz":300,"elapsed":2,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)"],"metadata":{"id":"E4QSkUCNGMNf","executionInfo":{"status":"ok","timestamp":1677800327157,"user_tz":300,"elapsed":335,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)"],"metadata":{"id":"VD0z-i-pGPNG","executionInfo":{"status":"ok","timestamp":1677800438748,"user_tz":300,"elapsed":2,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["embed_dim = 256\n","latent_dim = 2048\n","num_heads = 8\n","\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"],"metadata":{"id":"GSGp1jrVs2Io","executionInfo":{"status":"ok","timestamp":1677800468972,"user_tz":300,"elapsed":1222,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# embed_dim = 256\n","# latent_dim = 2048\n","# num_heads = 8\n","\n","# encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","# print(encoder_inputs.shape)\n","# x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","# print(x.shape)\n","# encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","# print(encoder_outputs.shape)\n","# encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","# decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","# print(encoder_inputs.shape)\n","# encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","# print(encoded_seq_inputs.shape)\n","# x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","# print(x.shape)\n","# x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n","# print(x.shape)\n","# x = layers.Dropout(0.5)(x)\n","# print(x.shape)\n","# decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","# print(decoder_outputs.shape)\n","# decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","# decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","# transformer = keras.Model(\n","#     [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n","# )"],"metadata":{"id":"QupvcMO5GRot","executionInfo":{"status":"ok","timestamp":1677800480247,"user_tz":300,"elapsed":3,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# Training our model\n"],"metadata":{"id":"98RbY68TGemX"}},{"cell_type":"code","source":["epochs = 30  # This should be at least 30 for convergence\n","\n","transformer.summary()\n","transformer.compile(\n","    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaEeVzvxGg2y","executionInfo":{"status":"ok","timestamp":1677800588334,"user_tz":300,"elapsed":311,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"93c599c2-73bf-4ff4-90d8-7c6bdbbef4b0"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," positional_embedding_2 (Positi  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n"," onalEmbedding)                                                                                   \n","                                                                                                  \n"," decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n","                                                                                                  \n"," transformer_encoder_1 (Transfo  (None, None, 256)   3155456     ['positional_embedding_2[0][0]'] \n"," rmerEncoder)                                                                                     \n","                                                                                                  \n"," model_3 (Functional)           (None, None, 15000)  12959640    ['decoder_inputs[0][0]',         \n","                                                                  'transformer_encoder_1[0][0]']  \n","                                                                                                  \n","==================================================================================================\n","Total params: 19,960,216\n","Trainable params: 19,960,216\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGOo7Wh3Gixe","outputId":"0ac27616-1fcb-4e2a-9fd8-ee69f9a97881","executionInfo":{"status":"ok","timestamp":1677803816126,"user_tz":300,"elapsed":3223731,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1302/1302 [==============================] - 102s 73ms/step - loss: 1.7274 - accuracy: 0.3962 - val_loss: 1.3959 - val_accuracy: 0.4781\n","Epoch 2/30\n","1302/1302 [==============================] - 94s 72ms/step - loss: 1.3996 - accuracy: 0.5078 - val_loss: 1.2274 - val_accuracy: 0.5508\n","Epoch 3/30\n","1302/1302 [==============================] - 94s 72ms/step - loss: 1.2370 - accuracy: 0.5626 - val_loss: 1.1216 - val_accuracy: 0.5864\n","Epoch 4/30\n","1302/1302 [==============================] - 93s 71ms/step - loss: 1.1414 - accuracy: 0.5964 - val_loss: 1.0837 - val_accuracy: 0.6072\n","Epoch 5/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 1.0924 - accuracy: 0.6186 - val_loss: 1.0546 - val_accuracy: 0.6196\n","Epoch 6/30\n","1302/1302 [==============================] - 93s 71ms/step - loss: 1.0641 - accuracy: 0.6338 - val_loss: 1.0473 - val_accuracy: 0.6257\n","Epoch 7/30\n","1302/1302 [==============================] - 93s 72ms/step - loss: 1.0434 - accuracy: 0.6457 - val_loss: 1.0379 - val_accuracy: 0.6315\n","Epoch 8/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 1.0270 - accuracy: 0.6556 - val_loss: 1.0321 - val_accuracy: 0.6363\n","Epoch 9/30\n","1302/1302 [==============================] - 94s 72ms/step - loss: 1.0117 - accuracy: 0.6638 - val_loss: 1.0288 - val_accuracy: 0.6401\n","Epoch 10/30\n","1302/1302 [==============================] - 93s 72ms/step - loss: 0.9992 - accuracy: 0.6715 - val_loss: 1.0296 - val_accuracy: 0.6451\n","Epoch 11/30\n","1302/1302 [==============================] - 93s 71ms/step - loss: 0.9857 - accuracy: 0.6780 - val_loss: 1.0207 - val_accuracy: 0.6474\n","Epoch 12/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.9745 - accuracy: 0.6836 - val_loss: 1.0225 - val_accuracy: 0.6493\n","Epoch 13/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.9624 - accuracy: 0.6895 - val_loss: 1.0315 - val_accuracy: 0.6482\n","Epoch 14/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.9506 - accuracy: 0.6947 - val_loss: 1.0242 - val_accuracy: 0.6504\n","Epoch 15/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.9397 - accuracy: 0.6995 - val_loss: 1.0308 - val_accuracy: 0.6476\n","Epoch 16/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.9281 - accuracy: 0.7036 - val_loss: 1.0288 - val_accuracy: 0.6545\n","Epoch 17/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.9197 - accuracy: 0.7079 - val_loss: 1.0307 - val_accuracy: 0.6526\n","Epoch 18/30\n","1302/1302 [==============================] - 92s 70ms/step - loss: 0.9093 - accuracy: 0.7119 - val_loss: 1.0315 - val_accuracy: 0.6501\n","Epoch 19/30\n","1302/1302 [==============================] - 92s 70ms/step - loss: 0.8995 - accuracy: 0.7160 - val_loss: 1.0355 - val_accuracy: 0.6494\n","Epoch 20/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.8897 - accuracy: 0.7190 - val_loss: 1.0294 - val_accuracy: 0.6548\n","Epoch 21/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.8783 - accuracy: 0.7233 - val_loss: 1.0358 - val_accuracy: 0.6547\n","Epoch 22/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.8740 - accuracy: 0.7257 - val_loss: 1.0412 - val_accuracy: 0.6536\n","Epoch 23/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.8649 - accuracy: 0.7292 - val_loss: 1.0495 - val_accuracy: 0.6545\n","Epoch 24/30\n","1302/1302 [==============================] - 92s 70ms/step - loss: 0.8566 - accuracy: 0.7320 - val_loss: 1.0419 - val_accuracy: 0.6559\n","Epoch 25/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.8479 - accuracy: 0.7350 - val_loss: 1.0529 - val_accuracy: 0.6547\n","Epoch 26/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.8399 - accuracy: 0.7376 - val_loss: 1.0564 - val_accuracy: 0.6516\n","Epoch 27/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.8327 - accuracy: 0.7399 - val_loss: 1.0576 - val_accuracy: 0.6556\n","Epoch 28/30\n","1302/1302 [==============================] - 92s 71ms/step - loss: 0.8292 - accuracy: 0.7424 - val_loss: 1.0673 - val_accuracy: 0.6547\n","Epoch 29/30\n","1302/1302 [==============================] - 92s 70ms/step - loss: 0.8218 - accuracy: 0.7448 - val_loss: 1.0735 - val_accuracy: 0.6489\n","Epoch 30/30\n","1302/1302 [==============================] - 91s 70ms/step - loss: 0.8141 - accuracy: 0.7474 - val_loss: 1.0674 - val_accuracy: 0.6527\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f363343b7c0>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["train_ds"],"metadata":{"id":"g4JfgS2SGtAS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spa_vocab = spa_vectorization.get_vocabulary()\n","spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n","max_decoded_sentence_length = 20\n","\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = eng_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n","        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = spa_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence\n","\n","\n","test_eng_texts = [pair[0] for pair in test_pairs]\n","for _ in range(30):\n","    input_sentence = random.choice(test_eng_texts)\n","    translated = decode_sequence(input_sentence)\n","    print(input_sentence,translated)"],"metadata":{"id":"l-5cpYFPG7fQ","executionInfo":{"status":"ok","timestamp":1677805070127,"user_tz":300,"elapsed":16623,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"74afd42a-d0ae-426d-ea3d-6b22cc47e322"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Do you want your money in coins? [start] quieres tu dinero en el [UNK] [end]\n","Did he learn Japanese as well? [start] Él hizo japoneses y tu blanco como [UNK] [end]\n","Tom shouldn't have driven Mary's car. [start] tom no deberías haber yo el auto [UNK] de mary [end]\n","Thank you. [start] lo gracias [end]\n","Do you think I'm beautiful? [start] tú crees que soy bella [end]\n","I'm really worried about my child. [start] estoy realmente preocupado por mi hijo [end]\n","Tom eats nothing but fruit. [start] tom no come nada que yo [UNK] [end]\n","That hurts. [start] tom duele [end]\n","This question is very simple. [start] esta pregunta es muy [UNK] [end]\n","This is the best ink. [start] este es la mejor ropa [end]\n","I told you not to move. [start] te dije que no se [UNK] [end]\n","Do I have to do this now? [start] tengo que hacerlo ahora [end]\n","This lake is among the deepest in the country. [start] este lago es entre el más [UNK] el país [end]\n","I'll see you at 2:30. [start] te veré en las dos y media [end]\n","This isn't my umbrella; it's somebody else's. [start] este no es mi paraguas es de lo que sea alguien [end]\n","Tom got very mad. [start] tom se puso muy enfadado [end]\n","A free port was established. [start] un [UNK] [UNK] fue [UNK] [end]\n","How easy is it to find a part-time job? [start] cómo se está [UNK] para hacer un trabajo a tiempo [UNK] [end]\n","My older sister goes jogging every day. [start] mi hermana mayor va a encontrar un día [UNK] [end]\n","They disguised themselves as fishermen and escaped in a boat. [start] ellos se [UNK] por que se [UNK] y [UNK] en un mercado [end]\n","Tom didn't want to do that. [start] tom no quería hacer eso [end]\n","The room was full of people. [start] la habitación estaba llena de gente llena [end]\n","A cold wind was blowing. [start] se me [UNK] un error [end]\n","After her husband's death, she brought up the two children all by herself. [start] después de la muerte de la policía ella [UNK] a ambos la vida [end]\n","They were playing a game of checkers. [start] estaban jugando a la partido de [UNK] [end]\n","Have your friends deserted you? [start] tu amigo te ha a ustedes [end]\n","The problem isn't Tom. [start] el problema no es tom [end]\n","I think Tom is going to win. [start] creo que tom va a ganar [end]\n","When was the last time you had a rest? [start] cuándo fue la última vez que hiciste un resto [end]\n","I hate surprise parties. [start] odio la tienda de mi mary [end]\n"]}]},{"cell_type":"code","source":["translated"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tExgMtSJ1tF7","executionInfo":{"status":"ok","timestamp":1677805000139,"user_tz":300,"elapsed":338,"user":{"displayName":"Thejaka Mahaulpatha","userId":"04179683276855370298"}},"outputId":"436dca07-4caa-46a3-852d-a769a6c92859"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[start] por qué está usted un suéter [end]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[],"metadata":{"id":"UclVFHCj-JL3"},"execution_count":null,"outputs":[]}]}